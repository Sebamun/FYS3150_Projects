\documentclass[norsk,a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} %for å bruke æøå
\usepackage[utf8]{inputenc}
\usepackage{graphicx} %for å inkludere grafikk
\usepackage{verbatim} %for å inkludere filer med tegn LaTeX ikke liker
\usepackage{mathpazo}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amsmath}
\usepackage{hyperref}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\bibliographystyle{plain}

\title{FYS3150-Project 1}
\author{Marcus Berget, Sebastian Amundsen, Andreas Wetzel}
\date{August 2020}
\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

In this project we will use numerical methods to solve the one dimensional Poisson equation. We will be rewriting the Dirichlet boundary conditions as a set of linear equations. Our numerical methods will have varying degrees of accuracy. We are going to compare our algorithms and the CPU time for the different numerical methods. 

\section{Method}

The one dimensional Poisson equation with Dirichlet boundary conditions is given by:

\begin{equation}
-u''(x)=f(x) \hspace{1cm} x \in (0,1) \hspace{1cm} u(0)=u(1)=0
 \label{eq:udd}
 \end{equation}

Let's define the discretized approximation to $u(x)$ as $v_i$, and to $f(x)$ as $f_i$. We can then make an approximation of the second derivative of $u$ given by:

\begin{equation}
\frac{-v_{i+1}+v_{i-1}-2v_i}{h^2}=f_i, \textrm{  where  } i=1,2,3......,n,
 \label{eq:2der}
 \end{equation}
 
 Here the step length of spacing is given by $h=1/(n+1)$ and the grid points is defined by $x_i=ih$. We can rewrite equation \ref{eq:2der} as a linear set of equations on the form $\textbf{A}\textbf{v}=\tilde{\textbf{b}}$:
\begin{align*}
\textbf{A}\textbf{v}&= \begin{bmatrix} 2 & -1 & 0 & \dots & \dots & 0 \\ -1 & 2 & -1 & 0 & \dots & \dots \\ 0 & -1 & 2 & -1 & 0 & \dots \\ \vdots & \vdots & \vdots & \ddots \\ 0 & \vdots & \vdots & -1 & 2 & -1 \\ 0 & \vdots & \vdots & 0 & -1 & 2  \end{bmatrix}
\begin{bmatrix} v_0 \\ v_1\\ v_2\\ \vdots \\ v_n \\ v_{n+1} \end{bmatrix}=\begin{bmatrix} 2v_0 - v_1 \\ -v_0+2v_1-v_2 \\ -v_1+2v_2-v_3 \\ \vdots \\ -v_{n-1}+2v_n-v_{n+1} \\ -v_n+2v_{n+1}
\end{bmatrix}\\ &=
\begin{bmatrix}h^2f_0 \\ h^2f_1\\ h^2f_2\\ \vdots \\ h^2f_n\\ h^2f_{n+1}\end{bmatrix} = \widetilde{\textbf{b}} \numberthis \label{eq:lineq}
\end{align*}

In our case we will use the source term $f(x)=100e^{-10x}$ which gives us a closed form solution $u(x)$ given by:

\begin{equation}
u(x)=1-(1-e^{-10})x-e^{-10x}
\label{eq:d_i}
\end{equation}

We will use this solution as a point of reference to discuss the accuracy of our numerical methods. 

\subsection{General algorithm for tri-diagonal matrix}

There exists an algorithm for solving generic sets of linear equations, but in the case for equation (\ref{eq:lineq})  where we have a tri-diagonal matrix we can use a different algorithm which decreases the amount of floating point operations needed. We denote the elements in the leading diagonal of A as $b_1, b_2, ..., b_n$, the elements above the leading diagonal as $a_2, a_3 ..., a_n$, and the elements below the leading diagonal as $c_1, c_2, ..., c_{n-1}$. The algorithm uses a forward substitution to replace the leading diagonal with elements denoted by $\tilde{b}_i$, and replacing the righthand side in with the elements $\tilde{f}_i$ as shown below:
\begin{align*}
\tilde{b}_i=b_i-\frac{a_ic_{i-1}}{\tilde{b}_{i-1}} \\
\tilde{f}_i=f_i-\frac{a_i\tilde{f}_{i-1}}{\tilde{b}_{i-1}}
\end{align*}
where $\tilde{b}_1=b_1$ and $\tilde{f}_i=f_i$. The algorithm then continues with a backward substitution which gives the solution:
\begin{align}
u_{i-1}=\frac{\tilde{f}_{i-1}-c_{i-1}u_i}{\tilde{b}_{i-1}}
\end{align}
\\

\subsection{Algorithm for specific tri-diagonal matrix}

In our special case we can implement a solver that is even simpler than what is described previously.  We will exploit the fact that the matrix has identical matrix elements along the diagonal and identical values for the non diagonal elements $\vec{e}_i$. In this case we can precalculate the new values for the updated matrix elements $d_i$ without taking into account the values for $\vec{e}_i$:

\begin{equation}
d_i = 2-\frac{1}{\tilde{d}_{i-1}}=\frac{i+1}{i}
 \label{eq:d_i}
 \end{equation}

Here the initial value is $\tilde{d}_1=2$. The new righthand side solution $\tilde{f}_i$ is given by:

\begin{equation}
\tilde{f}_i = f_i + \frac{(i-1)\tilde{f}_{i-1}}{i}
 \label{eq:f_i}
 \end{equation}

Here the initial value is $\tilde{f}_1=f_1$. The last step is to make a backward substitution which gives the final solution $u_i$:

\begin{equation}
u_{i-1}=\frac{i-1}{i}(\tilde{f}_{i-1}+\tilde{u})
 \label{eq:u_i-1}
 \end{equation}
 
 This method requires that we know the last value $u_n$ in the $u_i$ array. This value is given by $u_n=\tilde{f}_n/\tilde{b}_n$. 
 
 \subsection{Relative error}
 
 Algorithms have a varying degree of uncertainty. We will test how precise our algorithm is for the specific tri-diagonal matrix case. The numerical solution will be compared to the analytical solution given the relative error $\epsilon_i$:
 
 \begin{equation}
\epsilon_i = \log_{10}\bigg(\bigg|\frac{v_i-u_i}{u_i}\bigg|\bigg)
 \label{eq:f_i}
 \end{equation}
 
For the numerical $v_i$ and analytical $u_i$ function values. We wish to extract the max value of the relative error for varying numbers of grid points n. This will give us some information about how precise the numerical approximation is compared to the analytical solution.

 \subsection{LU decomposition}

We are now going to LU decomposition the matrixes 10 x 10, 100 x 100, 1000 x 1000 and 10 000 x 10 000. What the LU decomposition does, is that we can rewrite a matrix as the product of two other matrices L and U, like this:
\begin{align*}
\begin{bmatrix}
a_{11} & a_{12} & .... & a_{1n} \\
a_{21} & a_{22} & .... & a_{2n} \\
: & :& .... & : \\
a_{n1} & a_{n2} & .... & a_{nn} \\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & .... & 0 \\
l_{21} & 1 & .... & 0 \\
: & :& .... & : \\
l_{n1} & l_{n2} & .... & 1\\
\end{bmatrix}
\end{align*}gi


There are several reasons why we use LU decomposition instead of standard Gaussian elimination. First of all, it is straight forward to solve the determinant of a matrix. Second, if we still need to solve a set of linear equation with the same matrix, but with a different vector, the number of FLOPS is of order $n^3$. Where FLOPS is floating point operations per second. Where a such operation is the inverse. 

\section{Implementation}

All programs used is available at: \\
\url{https://github.com/Sebamun/FYS3150_Projekter}

We implement the algorithms numerically with varying values of grid points n.

Her må jeg si noe om hvorfor jeg valgte de grensene jeg valgte for den relative feilen. Vil ikke ha med ytterpunkter --> feilen blir gigantisk. Se på forholdet. 

\section{Results}

\subsection{General algorithm}

\subsection{Algorithm for specific tri-diagonal matrix}

 \subsection{Relative error}
 
  \subsection{LU decomposition}
  
  \section{Discussion}
  
  


\section{Concluding remarks}

\bibliography{referanser}
\end{document}

